# -*- coding: utf-8 -*-
import dspy
import os
import asyncio
from transformers import AutoTokenizer 

TOKENIZER_DIR = r"D:\download\deepseek_v3_tokenizer\deepseek_v3_tokenizer"
try:
    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_DIR, trust_remote_code=True)
except Exception as e:
    print(f"Tokenizer åŠ è½½å¤±è´¥: {e}")
    tokenizer = None

def get_token_count(text):
    """åˆ©ç”¨å®˜æ–¹åˆ†è¯å™¨è®¡ç®—ç²¾ç¡®é•¿åº¦"""
    if tokenizer and text:
        return len(tokenizer.encode(str(text)))
    return 0

class DisambiguationSignature(dspy.Signature):
    """
    å§“åæ¶ˆæ­§åˆ¤å®šå‡†åˆ™ï¼š
     æ ¸å¿ƒç›®æ ‡ï¼šåˆ¤æ–­å¾…å¤„ç†è®ºæ–‡çš„ä½œè€…æ˜¯å¦ä¸ºå€™é€‰äººæ± ä¸­çš„æŸä¸€ä½ã€‚
    è¯·æŒ‰ä»¥ä¸‹æƒé‡ä¼˜å…ˆçº§è¿›è¡Œåˆ¤å®šï¼š
    1. ã€é¦–è¦æƒé‡ã€‘åˆä½œè€…é‡åˆåº¦ï¼šè¿™æ˜¯åˆ¤å®šåŒä¸€äººçš„æœ€å¼ºè¯æ®ã€‚
    2. ã€æ¬¡è¦æƒé‡ã€‘ç ”ç©¶é¢†åŸŸçš„å»¶ç»­æ€§ï¼šå…³æ³¨æ ¸å¿ƒæŠ€æœ¯é¢†åŸŸçš„å…³è”ã€‚
    3. ã€ä¿®æ­£æƒé‡ã€‘æœºæ„ä¸€è‡´æ€§ï¼šæœºæ„ä»…ä½œä¸ºè¾…åŠ©å‚è€ƒã€‚è‹¥è®ºæ–‡æœºæ„ä¸ºç©ºï¼Œè¯·å®Œå…¨å¿½ç•¥æ­¤é¡¹å·®å¼‚ï¼Œä¸å¾—æ®æ­¤åˆ¤å®šä¸º new_authorã€‚
    4. ã€å¦å®šé¡¹ã€‘åªæœ‰åœ¨å‘ç°æ˜ç¡®çš„ç‰©ç†å†²çªï¼ˆå¦‚åœ°ç‚¹æ—¶é—´å®Œå…¨é‡å ä¸”ä¸å¯å…¼å¾—ï¼‰æ—¶ï¼Œæ‰è€ƒè™‘åˆ¤å®šä¸º new_authorã€‚

    """
    paper_info = dspy.InputField(desc="å¾…å¤„ç†è®ºæ–‡çš„æ ‡é¢˜ã€æœºæ„ç­‰")
    candidate_profiles = dspy.InputField(desc="å€™é€‰äººèƒŒæ™¯ç”»åƒæ± ï¼Œæ³¨æ„ï¼šå€™é€‰äººç”»åƒä¸­æ‹¬å·å†…çš„æ•°å­—ä»£è¡¨è¯¥ç‰¹å¾å‡ºç°çš„é¢‘æ¬¡ã€‚é¢‘æ¬¡è¶Šé«˜ï¼Œä»£è¡¨è¯¥ç‰¹å¾ï¼ˆå¦‚åˆä½œè€…æˆ–ç ”ç©¶ä¸»é¢˜ï¼‰å¯¹è¯¥å€™é€‰äººçš„ä»£è¡¨æ€§è¶Šå¼ºã€‚")
    best_id = dspy.OutputField(desc="åŒ¹é…æˆåŠŸçš„ ID æˆ– 'new_author'")
    reasoning = dspy.OutputField(desc="åˆ¤å®šä¾æ®ï¼ˆç®€è¦ï¼‰ ")

class Disambiguator(dspy.Module):
    def __init__(self):
        super().__init__()
        # ä½¿ç”¨ Predict æé«˜ V3 çš„å“åº”é€Ÿåº¦ï¼Œå¦‚éœ€åˆ†æåˆ™ç”¨ ChainOfThought
        self.predictor = dspy.Predict(DisambiguationSignature)
    
    def __call__(self, paper_info, candidate_profiles):
        return self.predictor(paper_info=paper_info, candidate_profiles=candidate_profiles)

async def ask_deepseek_async(task_id, paper_info, candidate_profiles, current_index=0, total_count=0):
    """
    å¼‚æ­¥å°è£…å±‚ï¼šåˆ©ç”¨ dspy.asyncify å®ç°å¹¶å‘è°ƒç”¨
    """
    # --- ç›‘æ§ A: åŸºç¡€æ•°æ®å‡†å¤‡ ---
    num_candidates = len(candidate_profiles)
    paper_text = str(paper_info)
    profiles_text = "\n".join([f"ã€ID: {k}ã€‘\n{v}" for k, v in candidate_profiles.items()])
    
    # è®¡ç®—è¾“å…¥ Token
    in_tokens = get_token_count(paper_text + profiles_text)
    
    # æ‰“å°æ—¶ä½¿ç”¨â€œå·²æäº¤â€å­—æ ·ï¼Œå› ä¸ºå¼‚æ­¥æ¨¡å¼ä¸‹å¤šä¸ªä»»åŠ¡ä¼šåŒæ—¶æ˜¾ç¤ºåœ¨è¿™é‡Œ
    print(f"[{current_index}/{total_count}] ğŸš€ ä»»åŠ¡æäº¤: {task_id} | å€™é€‰äºº: {num_candidates} | Tokens: {in_tokens}")

    # --- ç›‘æ§ B: å¼‚æ­¥è°ƒç”¨ DSPy ---
    model = Disambiguator()
    
    # ä½¿ç”¨ dspy.asyncify å°†åŒæ­¥æ¨¡å—è½¬ä¸ºå¼‚æ­¥
    # è¿™å…è®¸æˆ‘ä»¬åœ¨ await æ—¶é‡Šæ”¾äº‹ä»¶å¾ªç¯ï¼Œè®©å…¶ä»–ä»»åŠ¡ä¹Ÿèƒ½å¯åŠ¨
    async_model = dspy.asyncify(model)
    
    try:
        # å¼‚æ­¥ç­‰å¾…ç»“æœè¿”å›
        prediction = await async_model(paper_info=paper_text, candidate_profiles=profiles_text)
        
        # --- ç›‘æ§ C: ç»“æœå¤„ç† ---
        out_tokens = get_token_count(prediction.best_id + prediction.reasoning)
        
        # æ¸…æ´—ç»“æœ
        res_id = prediction.best_id.strip().replace("'", "").replace('"', "")
        
        # ç»Ÿä¸€è§„èŒƒåŒ–ï¼šå¦‚æœæ˜¯ NILã€None æˆ– NEW_AUTHORï¼Œç»Ÿä¸€è¿”å› None ä¾›é€»è¾‘åˆ¤æ–­
        # æ³¨æ„ï¼šè¿™é‡Œå¢åŠ å¯¹ NEW_AUTHOR çš„è¯†åˆ«
        if res_id.upper() in ["NIL", "NONE", "NEW_AUTHOR"]:
            final_id = None
        else:
            final_id = res_id
            
        return final_id, prediction.reasoning, num_candidates, in_tokens, out_tokens

    except Exception as e:
        print(f"âŒ ä»»åŠ¡ {task_id} API è°ƒç”¨å¼‚å¸¸: {e}")
        # å‘ä¸ŠæŠ›å‡ºå¼‚å¸¸ï¼Œè®© main.py çš„ try-except æ•è·
        raise e